{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "x=np.empty([1000,28,28,3])\n",
    "y=np.empty([1000,96])\n",
    "g=np.empty([1000,96])\n",
    "y_int=np.empty([1000])\n",
    "g_int=np.empty([1000])\n",
    "\n",
    "first = 1\n",
    "for root, dirs, files in os.walk(\"/Users/momo/Downloads/openCV\"):\n",
    "\tos.chdir(root)\n",
    "\timages = np.array([cv2.imread(file) for file in glob.glob(root+\"/*.jpg\")])\n",
    "\tnum_of_images=images.shape[0]\n",
    "\tif num_of_images == 0:\n",
    "\t\tcontinue\n",
    "\telse:\n",
    "\t\tif first == 1:\n",
    "\t\t\tx = images\n",
    "\t\t\tname = os.path.basename(os.path.normpath(root))\n",
    "\t\t\ty.fill(0)\n",
    "\t\t\tnum=0\n",
    "\t\t\tfor i in range(0,999):\n",
    "\t\t\t\ty[i,num]=1\n",
    "\t\t\ty_int.fill(num)\n",
    "\t\t\td={'strname':name,'intname':num}\n",
    "\t\t\tcorr = pd.DataFrame(data = d,index=[num])\n",
    "\t\t\tfirst = 0\n",
    "\t\t\tnum=num+1\n",
    "\t\telse:\n",
    "\t\t\tx = np.concatenate((x,images),axis=0)\n",
    "\t\t\tname = os.path.basename(os.path.normpath(root))\n",
    "\t\t\tg.fill(0)\n",
    "\t\t\tfor i in range(0,999):\n",
    "\t\t\t\tg[i,num]=1\n",
    "\t\t\ty=np.concatenate((y,g),axis=0)\n",
    "\t\t\tg_int.fill(num)\n",
    "\t\t\ty_int=np.concatenate((y_int,g_int),axis=0)\n",
    "\t\t\td={'strname' : name,'intname':num}\n",
    "\t\t\tnewcorr = pd.DataFrame(data = d,index=[num])\n",
    "\t\t\tcorr = corr.append(newcorr)\n",
    "\t\t\tnum=num+1\n",
    "x=np.reshape(x,[96000,2352])\n",
    "#images=x\n",
    "#labels=y\n",
    "#print(num)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test,y_int_train,y_int_test = train_test_split(x, y, y_int, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of pixels in each dimension of an image.\n",
    "img_size = 28\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 2352\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = [28,28,3]\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 96\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = x_test[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = y_int_test[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    strname  intname\n",
      "64  1_0_3_0       64\n",
      "    strname  intname\n",
      "65  0_0_4_0       65\n"
     ]
    }
   ],
   "source": [
    "print(corr.loc[[64]]) \n",
    "print(corr.loc[[65]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='ex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(ex, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/momo/.virtualenvs/cv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-2dd067a7547b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2352)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(x,y,y_int,batch_size):\n",
    "        \"\"\"\n",
    "        Create a random batch of training-data.\n",
    "\n",
    "        :param batch_size: Number of images in the batch.\n",
    "        :return: 3 numpy arrays (x, y, y_cls)\n",
    "        \"\"\"\n",
    "        num_train = 72000\n",
    "        # Create a random index into the training-set.\n",
    "        idx = np.random.randint(low=0, high=num_train, size=batch_size)\n",
    "\n",
    "        # Use the index to lookup random training-data.\n",
    "        x_batch = x[idx]\n",
    "        y_batch = y[idx]\n",
    "        y_int_batch = y_int[idx]\n",
    "\n",
    "        return x_batch, y_batch, y_int_batch\n",
    "        #return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_batch = random_batch(x_train,batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch,y_true_batch,_ = random_batch(x_train,y_train,y_int_train,batch_size=train_batch_size)\n",
    "        \n",
    "        #y_true_batch= random_batch(y_train,batch_size=train_batch_size)\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {ex: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ima = x_test[1:10, :]\n",
    "lab = y_test[1:10, :]\n",
    "#print(ima.shape)\n",
    "#print(lab.shape)\n",
    "feed_dict = {ex: ima, y_true: lab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = 24000\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = x_test[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = y_test[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {ex: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = y_int_test\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 1.2% (298 / 24000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   7.8%\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    101, Training Accuracy:  39.1%\n",
      "Optimization Iteration:    201, Training Accuracy:  79.7%\n",
      "Optimization Iteration:    301, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    401, Training Accuracy:  89.1%\n",
      "Optimization Iteration:    501, Training Accuracy:  98.4%\n",
      "Optimization Iteration:    601, Training Accuracy:  93.8%\n",
      "Optimization Iteration:    701, Training Accuracy:  87.5%\n",
      "Optimization Iteration:    801, Training Accuracy:  92.2%\n",
      "Optimization Iteration:    901, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   1001, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1101, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1201, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   1301, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1401, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   1501, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1601, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   1701, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   1801, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   1901, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   2001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   2101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2201, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   2301, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   2401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   2501, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   2601, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   2701, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2801, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2901, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   3001, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   3101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   3401, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   3501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   3601, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   3701, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   3801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4001, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   4101, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   4201, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   4301, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4501, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   4601, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   4701, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   4801, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5001, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5201, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   5301, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   5401, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   5501, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   5601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   5701, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   5801, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   5901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   6201, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   6301, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   6401, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   6501, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   6601, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6701, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   6801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   6901, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   7001, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   7101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   7201, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   7301, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   7401, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   7501, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   7601, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   7701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   7801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   7901, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   8001, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   8101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   8201, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   8301, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   8401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   8501, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   8601, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   8701, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   8801, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   8901, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   9001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   9101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   9201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9301, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9401, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   9501, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   9601, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   9701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   9801, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   9901, Training Accuracy:  96.9%\n",
      "Optimization Iteration:  10001, Training Accuracy:  98.4%\n",
      "Time usage: 0:10:52\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 95.5% (22915 / 24000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
